{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d6fab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570df7cc",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17f12fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nltk.data.find('tokenizers/punkt_tab')\n",
    "except LookupError:\n",
    "    nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72097d95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\" I am Kabir 's.\", 'From Haryana.', 'Studying NLP.']\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "    Tokenisation: \n",
    "    paragraph -> sentences\n",
    "    sentence -> words\n",
    "\"\"\"\n",
    "corpus = \"\"\" I am Kabir 's.\n",
    "    From Haryana.\n",
    "    Studying NLP.\n",
    "\"\"\"\n",
    "documents = sent_tokenize(corpus)\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1cd9f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'Kabir', \"'s\", '.', 'From', 'Haryana', '.', 'Studying', 'NLP', '.']\n",
      "['I', 'am', 'Kabir', \"'\", 's', '.', 'From', 'Haryana', '.', 'Studying', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "words1 = word_tokenize(corpus)  \n",
    "print(words1)\n",
    "words2 = wordpunct_tokenize(corpus)     # all punc considered separate words\n",
    "print(words2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5a058d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'Kabir', \"'s.\", 'From', 'Haryana.', 'Studying', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "tokeniser = TreebankWordTokenizer()     # . is not considered separate word\n",
    "words3 = tokeniser.tokenize(corpus)\n",
    "print(words3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "156ebe6e",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "### Process of Reducing word to its stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad627b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eating\",\"eats\",\"eaten\",\"writing\",\"writes\",\"programming\",\"programs\",\"finally\",\"finalised\",\"history\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "843bd83a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------>eat\n",
      "eats------>eat\n",
      "eaten------>eaten\n",
      "writing------>write\n",
      "writes------>write\n",
      "programming------>program\n",
      "programs------>program\n",
      "finally------>final\n",
      "finalised------>finalis\n",
      "history------>histori\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "# Porter Stemmer\n",
    "stemming = PorterStemmer()\n",
    "for word in words:\n",
    "    print(word+\"------>\"+stemming.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "055ca042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'congratul'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemming.stem('congratulations')    # disadvantage: changes meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7329b806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eat'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import RegexpStemmer\n",
    "\n",
    "# Regex Stemmer\n",
    "reg_stemmer = RegexpStemmer(r\"ing$|s$|e$|able$\",min = 4)\n",
    "reg_stemmer.stem('eating')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6421c3f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------>eat\n",
      "eats------>eat\n",
      "eaten------>eaten\n",
      "writing------>write\n",
      "writes------>write\n",
      "programming------>program\n",
      "programs------>program\n",
      "finally------>final\n",
      "finalised------>finalis\n",
      "history------>histori\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "# Snowball Stemmer\n",
    "snow_stemmer = SnowballStemmer('english')\n",
    "for word in words:\n",
    "    print(word+\"------>\"+snow_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19403328",
   "metadata": {},
   "source": [
    "## Lemmatizer\n",
    "#### Lemmatization is like stemming, where output will be exact root word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e41e2fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/kabirsprakash/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n"
     ]
    }
   ],
   "source": [
    "# Q&A, text summarisation, Chatbots\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer  = WordNetLemmatizer()\n",
    "\"\"\" \n",
    "    POS tags :-\n",
    "    n - nouns\n",
    "    v - verb\n",
    "    a - adjective\n",
    "    r - adverb\n",
    "\"\"\"\n",
    "print(lemmatizer.lemmatize(\"going\",pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8eefd3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating----->eating\n",
      "eats----->eats\n",
      "eaten----->eaten\n",
      "writing----->writing\n",
      "writes----->writes\n",
      "programming----->programming\n",
      "programs----->program\n",
      "finally----->finally\n",
      "finalised----->finalised\n",
      "history----->history\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"----->\"+lemmatizer.lemmatize(word)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717583a8",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "775d76e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/kabirsprakash/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para = \"\"\" My dear young friends, I have always believed that dreams are not those which you see while sleeping, but those that do not let you sleep. Each one of you has within you the power to shape your future, to ignite your imagination and work with dedication. When I was a boy in Rameswaram, no one could have predicted that I would one day become the President of India. It was possible because of the vision I had, and the support of my teachers and family. Education is the most powerful weapon that can transform a child from a small village into a scientist, a leader, or an entrepreneur. Do not underestimate the value of hard work and perseverance. Failures are part of life. If you never fail, you will never learn. I want every youth in this country to take responsibility — to be courageous, to innovate, to think big. The nation needs dreamers who are also doers. We need individuals who are not afraid to question, to challenge the status quo, and to walk the untrodden path. India’s future lies in the hands of its youth — your hands. So dream big, aim high, and let your thoughts and actions be guided by integrity, compassion, and a relentless pursuit of excellence.\"\"\"\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8cbfe0a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0dbcd5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "sentences = nltk.sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37fb09ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my dear young friend , i alway believ dream see sleep , let sleep .', 'each one within power shape futur , ignit imagin work dedic .', 'when i boy rameswaram , one could predict i would one day becom presid india .', 'it possibl vision i , support teacher famili .', 'educ power weapon transform child small villag scientist , leader , entrepreneur .', 'do underestim valu hard work persever .', 'failur part life .', 'if never fail , never learn .', 'i want everi youth countri take respons — courag , innov , think big .', 'the nation need dreamer also doer .', 'we need individu afraid question , challeng statu quo , walk untrodden path .', 'india ’ futur lie hand youth — hand .', 'so dream big , aim high , let thought action guid integr , compass , relentless pursuit excel .']\n"
     ]
    }
   ],
   "source": [
    "# Apply stopwords and filter and then apply stemming\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [stemmer.stem(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = ' '.join(words)\n",
    "\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58e2fd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my dear young friends , i always believe dream see sleep , let sleep .', 'each one within power shape future , ignite imagination work dedication .', 'when i boy rameswaram , one could predict i would one day become president india .', 'it possible vision i , support teachers family .', 'education powerful weapon transform child small village scientist , leader , entrepreneur .', 'do underestimate value hard work perseverance .', 'failures part life .', 'if never fail , never learn .', 'i want every youth country take responsibility — courageous , innovate , think big .', 'the nation need dreamers also doers .', 'we need individuals afraid question , challenge status quo , walk untrodden path .', 'india ’ future lie hand youth — hand .', 'so dream big , aim high , let thoughts action guide integrity , compassion , relentless pursuit excellence .']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "sentences = nltk.sent_tokenize(para)\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word.lower(),pos='v') for word in words if word not in set(stopwords.words('english'))]\n",
    "    sentences[i] = \" \".join(words)\n",
    " \n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57de6e9e",
   "metadata": {},
   "source": [
    "### POS Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e0afedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b935c77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/kabirsprakash/nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My', 'PRP$'), ('dear', 'JJ'), ('young', 'JJ'), ('friends', 'NNS'), (',', ','), ('I', 'PRP'), ('always', 'RB'), ('believed', 'VBD'), ('dreams', 'NNS'), ('see', 'VBP'), ('sleeping', 'VBG'), (',', ','), ('let', 'VB'), ('sleep', 'NN'), ('.', '.')]\n",
      "[('Each', 'DT'), ('one', 'CD'), ('within', 'IN'), ('power', 'NN'), ('shape', 'NN'), ('future', 'NN'), (',', ','), ('ignite', 'JJ'), ('imagination', 'NN'), ('work', 'NN'), ('dedication', 'NN'), ('.', '.')]\n",
      "[('When', 'WRB'), ('I', 'PRP'), ('boy', 'VBP'), ('Rameswaram', 'NNP'), (',', ','), ('one', 'CD'), ('could', 'MD'), ('predicted', 'VB'), ('I', 'PRP'), ('would', 'MD'), ('one', 'CD'), ('day', 'NN'), ('become', 'VB'), ('President', 'NNP'), ('India', 'NNP'), ('.', '.')]\n",
      "[('It', 'PRP'), ('possible', 'JJ'), ('vision', 'NN'), ('I', 'PRP'), (',', ','), ('support', 'NN'), ('teachers', 'NNS'), ('family', 'NN'), ('.', '.')]\n",
      "[('Education', 'NN'), ('powerful', 'JJ'), ('weapon', 'JJ'), ('transform', 'NN'), ('child', 'NN'), ('small', 'JJ'), ('village', 'NN'), ('scientist', 'NN'), (',', ','), ('leader', 'NN'), (',', ','), ('entrepreneur', 'NN'), ('.', '.')]\n",
      "[('Do', 'VB'), ('underestimate', 'JJ'), ('value', 'NN'), ('hard', 'JJ'), ('work', 'NN'), ('perseverance', 'NN'), ('.', '.')]\n",
      "[('Failures', 'NNS'), ('part', 'NN'), ('life', 'NN'), ('.', '.')]\n",
      "[('If', 'IN'), ('never', 'RB'), ('fail', 'VBP'), (',', ','), ('never', 'RB'), ('learn', 'NN'), ('.', '.')]\n",
      "[('I', 'PRP'), ('want', 'VBP'), ('every', 'DT'), ('youth', 'NN'), ('country', 'NN'), ('take', 'VB'), ('responsibility', 'NN'), ('—', 'NNP'), ('courageous', 'JJ'), (',', ','), ('innovate', 'JJ'), (',', ','), ('think', 'VBP'), ('big', 'JJ'), ('.', '.')]\n",
      "[('The', 'DT'), ('nation', 'NN'), ('needs', 'VBZ'), ('dreamers', 'NNS'), ('also', 'RB'), ('doers', 'NNS'), ('.', '.')]\n",
      "[('We', 'PRP'), ('need', 'VBP'), ('individuals', 'NNS'), ('afraid', 'JJ'), ('question', 'NN'), (',', ','), ('challenge', 'NN'), ('status', 'NN'), ('quo', 'NN'), (',', ','), ('walk', 'VBP'), ('untrodden', 'JJ'), ('path', 'NN'), ('.', '.')]\n",
      "[('India', 'NNP'), ('’', 'NNP'), ('future', 'NN'), ('lies', 'VBZ'), ('hands', 'NNS'), ('youth', 'RB'), ('—', 'JJ'), ('hands', 'NNS'), ('.', '.')]\n",
      "[('So', 'RB'), ('dream', 'RB'), ('big', 'JJ'), (',', ','), ('aim', 'JJ'), ('high', 'JJ'), (',', ','), ('let', 'VB'), ('thoughts', 'NNS'), ('actions', 'NNS'), ('guided', 'VBD'), ('integrity', 'NN'), (',', ','), ('compassion', 'NN'), (',', ','), ('relentless', 'NN'), ('pursuit', 'NN'), ('excellence', 'NN'), ('.', '.')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "# Finding POS tags\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "    pos_tag = nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e594f0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Taj', 'NNP'), ('Mahal', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('monument', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "ex_ls = []\n",
    "for word in \"Taj Mahal is a beautiful monument\".split():\n",
    "    ex_ls.append(word)\n",
    "print(nltk.pos_tag(ex_ls))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abfdb78",
   "metadata": {},
   "source": [
    "### Named Entity Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5339be22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /Users/kabirsprakash/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n",
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/kabirsprakash/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px\" version=\"1.1\" viewBox=\"0,0,1872.0,168.0\" width=\"1872px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"3.84615%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Despite</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"1.92308%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.99145%\" x=\"3.84615%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">heavy</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.34188%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.5641%\" x=\"6.83761%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">rain</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.11966%\" y1=\"20px\" y2=\"48px\" /><svg width=\"1.7094%\" x=\"9.40171%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10.2564%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.83761%\" x=\"11.1111%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">GPE</text></svg><svg width=\"31.25%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">San</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.625%\" y1=\"20px\" y2=\"48px\" /><svg width=\"68.75%\" x=\"31.25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Francisco</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.625%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.5299%\" y1=\"20px\" y2=\"48px\" /><svg width=\"1.28205%\" x=\"17.9487%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"18.5897%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.13675%\" x=\"19.2308%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.2991%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.70085%\" x=\"21.3675%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">resilient</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"23.7179%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.99145%\" x=\"26.0684%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">crowd</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.5641%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.84615%\" x=\"29.0598%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">cheered</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"30.9829%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.4188%\" x=\"32.906%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">loudly</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">RB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.6154%\" y1=\"20px\" y2=\"48px\" /><svg width=\"1.7094%\" x=\"36.3248%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">as</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"37.1795%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.12821%\" x=\"38.0342%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"50%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Elon</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"20px\" y2=\"48px\" /><svg width=\"50%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Musk</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40.5983%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.2735%\" x=\"43.1624%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">unveiled</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"45.2991%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.4188%\" x=\"47.4359%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PERSON</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">Tesla</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"49.1453%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.13675%\" x=\"50.8547%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">'s</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">POS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"51.9231%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.4188%\" x=\"52.9915%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">latest</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJS</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.7009%\" y1=\"20px\" y2=\"48px\" /><svg width=\"5.98291%\" x=\"56.4103%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">self-driving</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"59.4017%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.70085%\" x=\"62.3932%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">prototype</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.7436%\" y1=\"20px\" y2=\"48px\" /><svg width=\"1.28205%\" x=\"67.094%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.735%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.99145%\" x=\"68.3761%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">which</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">WDT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"69.8718%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.13675%\" x=\"71.3675%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">he</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"72.4359%\" y1=\"20px\" y2=\"48px\" /><svg width=\"3.84615%\" x=\"73.5043%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">claimed</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75.4274%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.99145%\" x=\"77.3504%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">would</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">MD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.8462%\" y1=\"20px\" y2=\"48px\" /><svg width=\"6.41026%\" x=\"80.3419%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">revolutionize</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VB</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"83.547%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.99145%\" x=\"86.7521%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">urban</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.2479%\" y1=\"20px\" y2=\"48px\" /><svg width=\"4.70085%\" x=\"89.7436%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">transport</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.094%\" y1=\"20px\" y2=\"48px\" /><svg width=\"1.7094%\" x=\"94.4444%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">by</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"95.2991%\" y1=\"20px\" y2=\"48px\" /><svg width=\"2.5641%\" x=\"96.1538%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">2026</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"97.4359%\" y1=\"20px\" y2=\"48px\" /><svg width=\"1.28205%\" x=\"98.7179%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"20px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"99.359%\" y1=\"20px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [('Despite', 'IN'), ('heavy', 'JJ'), ('rain', 'NN'), ('in', 'IN'), Tree('GPE', [('San', 'NNP'), ('Francisco', 'NNP')]), (',', ','), ('the', 'DT'), ('resilient', 'NN'), ('crowd', 'NN'), ('cheered', 'VBD'), ('loudly', 'RB'), ('as', 'IN'), Tree('PERSON', [('Elon', 'NNP'), ('Musk', 'NNP')]), ('unveiled', 'VBD'), Tree('PERSON', [('Tesla', 'NNP')]), (\"'s\", 'POS'), ('latest', 'JJS'), ('self-driving', 'JJ'), ('prototype', 'NN'), (',', ','), ('which', 'WDT'), ('he', 'PRP'), ('claimed', 'VBD'), ('would', 'MD'), ('revolutionize', 'VB'), ('urban', 'JJ'), ('transport', 'NN'), ('by', 'IN'), ('2026', 'CD'), ('.', '.')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker_tab')\n",
    "nltk.download('words')\n",
    "\n",
    "words = word_tokenize(\"Despite heavy rain in San Francisco, the resilient crowd cheered loudly as Elon Musk unveiled Tesla's latest self-driving prototype, which he claimed would revolutionize urban transport by 2026.\")\n",
    "nltk.ne_chunk(nltk.pos_tag(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88445c54",
   "metadata": {},
   "source": [
    "### Word Embeddings\n",
    "used for representation of words for text analysis typically in form a real valued vector that encodes meaning of word such that words are closer in vector space are expected to have similar meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1234965",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8406ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "wv = api.load('word2vec-google-news-300')\n",
    "vec_king = wv['king']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ca1c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(wv['king'])\n",
    "print(wv.most_similar('cricket'))\n",
    "print(wv.similarity('hockey','sports'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
